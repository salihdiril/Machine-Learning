{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMflmaxYvHGl/rxnzgHBbYz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IqIPVvFIjADX","executionInfo":{"status":"ok","timestamp":1667396041925,"user_tz":-180,"elapsed":19543,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"b6c592ba-b0f7-4d6e-d4ac-bc88f54657d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["import os\n","import math\n","import numpy as np\n","import random\n","import torch\n","from torch import nn\n","import torch.nn.functional as F"],"metadata":{"id":"6PpOi6fEjAz2","executionInfo":{"status":"ok","timestamp":1667396077229,"user_tz":-180,"elapsed":17,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["text = [\"hey how are you\", \"good I am fine\", \"have a nice day\"]\n","\n","# Join all the sentences together and extract the unique characters from the combined sentence\n","chars = set(\"\".join(text))\n","\n","# Creating a dictionary that maps integers to the characters\n","int2char = dict(enumerate(chars))\n","\n","# Creating another dictionary that maps characters to integers\n","char2int = {char: idx for idx, char in int2char.items()}"],"metadata":{"id":"GoeBMrsGjHzv","executionInfo":{"status":"ok","timestamp":1667396468910,"user_tz":-180,"elapsed":5,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["int2char"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BIfq_R1okvt3","executionInfo":{"status":"ok","timestamp":1667396474695,"user_tz":-180,"elapsed":17,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"9c3dd3d2-8505-428c-f10d-acf1d46667d2"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 'm',\n"," 1: 'I',\n"," 2: 'u',\n"," 3: 'f',\n"," 4: 'h',\n"," 5: 'd',\n"," 6: 'o',\n"," 7: 'e',\n"," 8: 'w',\n"," 9: 'a',\n"," 10: 'i',\n"," 11: 'n',\n"," 12: 'g',\n"," 13: 'c',\n"," 14: ' ',\n"," 15: 'r',\n"," 16: 'y',\n"," 17: 'v'}"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["char2int"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UXB8g8kokxHU","executionInfo":{"status":"ok","timestamp":1667396484108,"user_tz":-180,"elapsed":4,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"5ebe5848-1e12-40a1-db33-0bc741d43fc9"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'m': 0,\n"," 'I': 1,\n"," 'u': 2,\n"," 'f': 3,\n"," 'h': 4,\n"," 'd': 5,\n"," 'o': 6,\n"," 'e': 7,\n"," 'w': 8,\n"," 'a': 9,\n"," 'i': 10,\n"," 'n': 11,\n"," 'g': 12,\n"," 'c': 13,\n"," ' ': 14,\n"," 'r': 15,\n"," 'y': 16,\n"," 'v': 17}"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Finding the length of the longest string in our data\n","maxlen = len(max(text, key=len))\n","maxlen"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9GHQcBZkzd2","executionInfo":{"status":"ok","timestamp":1667396607473,"user_tz":-180,"elapsed":10,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"b2164b9a-a8e9-484a-bdab-b262446f3a81"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Padding\n","\n","# A simple loop that loops through the list of sentences and adds a ' ' whitespace until the length of\n","# the sentence matches the length of the longest sentence\n","for i in range(len(text)):\n","  while len(text[i])<maxlen:\n","    text[i] += \" \""],"metadata":{"id":"tFmbGgT0lRUr","executionInfo":{"status":"ok","timestamp":1667396759821,"user_tz":-180,"elapsed":18,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GqI8NrrYl20a","executionInfo":{"status":"ok","timestamp":1667396766733,"user_tz":-180,"elapsed":386,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"77577a3f-bb6f-468e-9ae0-d0d18e531f37"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['hey how are you', 'good I am fine ', 'have a nice day']"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# Creating lists that will hold our input and target sequences\n","input_seq = []\n","target_seq = []\n","\n","for i in range(len(text)):\n","  # Remove last character for input sequence\n","  input_seq.append(text[i][:-1])\n","\n","  # Remove first character for target sequence\n","  target_seq.append(text[i][1:])\n","  print(\"Input Sequence: {}\\nTarget Sequence: {}\".format(input_seq[i], target_seq[i]))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zOxucpjql4ZK","executionInfo":{"status":"ok","timestamp":1667396995468,"user_tz":-180,"elapsed":20,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"c08e8407-6e75-4d24-d15e-1b0c3e250724"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Input Sequence: hey how are yo\n","Target Sequence: ey how are you\n","Input Sequence: good I am fine\n","Target Sequence: ood I am fine \n","Input Sequence: have a nice da\n","Target Sequence: ave a nice day\n"]}]},{"cell_type":"code","source":["for i in range(len(text)):\n","  input_seq[i] = [char2int[character] for character in input_seq[i]]\n","  target_seq[i] = [char2int[character] for character in target_seq[i]]"],"metadata":{"id":"2EGx6PEOmwTw","executionInfo":{"status":"ok","timestamp":1667397137801,"user_tz":-180,"elapsed":423,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["input_seq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pC0zOwCjnTGS","executionInfo":{"status":"ok","timestamp":1667397144795,"user_tz":-180,"elapsed":17,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"efd925c8-88b3-473f-a447-28106c187a6b"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[4, 7, 16, 14, 4, 6, 8, 14, 9, 15, 7, 14, 16, 6],\n"," [12, 6, 6, 5, 14, 1, 14, 9, 0, 14, 3, 10, 11, 7],\n"," [4, 9, 17, 7, 14, 9, 14, 11, 10, 13, 7, 14, 5, 9]]"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["Before encoding our input sequence into one-hot vectors, we'll define 3 key variables:\n","\n","    dict_size: Dictionary size - The number of unique characters that we have in our text\n","        This will determine the one-hot vector size as each character will have an assigned index in that vector\n","    seq_len: The length of the sequences that we're feeding into the model\n","        As we standardized the length of all our sentences to be equal to the longest sentences, this value will be the max length - 1 as we removed the last character input as well\n","    batch_size: The number of sentences that we defined and are going to feed into the model as a batch\n"],"metadata":{"id":"Ch5NNk-Bnnux"}},{"cell_type":"code","source":["dict_size = len(char2int)\n","seq_len = maxlen - 1\n","batch_size = len(text)\n","\n","def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n","  # Creating a multi-dimensional array of zeros with the desired output shape\n","  features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n","\n","  # Replacing the 0 at the relevant character index with a 1 to represent that character\n","  for i in range(batch_size):\n","    for u in range(seq_len):\n","      features[i, u, sequence[i][u]] = 1\n","  return features"],"metadata":{"id":"xE57MwOhnUk-","executionInfo":{"status":"ok","timestamp":1667397593018,"user_tz":-180,"elapsed":316,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["x = [\n","    [\n","        [1, 2, 3, 4],\n","        [5, 6, 7, 8]\n","    ],\n","    [\n","        [9, 10, 11, 12],\n","        [13, 14, 15, 16]\n","    ],\n","    [ \n","        [17, 18, 19, 20],\n","        [21, 22, 23, 24]\n","    ] \n","]\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AtdmzcF-rCB3","executionInfo":{"status":"ok","timestamp":1667398342310,"user_tz":-180,"elapsed":291,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"cd256e44-c79e-4a99-9fc6-4f3965becc82"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[[1, 2, 3, 4], [5, 6, 7, 8]],\n"," [[9, 10, 11, 12], [13, 14, 15, 16]],\n"," [[17, 18, 19, 20], [21, 22, 23, 24]]]"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["x[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mw5h0UjQr8EE","executionInfo":{"status":"ok","timestamp":1667398361262,"user_tz":-180,"elapsed":444,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"f6723c08-956b-4bb9-f3b9-efc5d9b6ee81"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[9, 10, 11, 12], [13, 14, 15, 16]]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["type(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"813rf_Her_lw","executionInfo":{"status":"ok","timestamp":1667398418513,"user_tz":-180,"elapsed":15,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"c6738f36-b196-413d-942f-bf3a96d18505"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["x = np.array(x)\n","type(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D53G5Od6sM4A","executionInfo":{"status":"ok","timestamp":1667398449950,"user_tz":-180,"elapsed":480,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"a6566cff-9d03-4e5d-eb92-908d9e7e5cd0"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["x[1, 1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EGx6R2J5sU9e","executionInfo":{"status":"ok","timestamp":1667398460282,"user_tz":-180,"elapsed":19,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"207d9a0c-555c-44e6-ef31-aa6ffa44b12b"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([13, 14, 15, 16])"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["x[1, 1, 2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GKgJw46qsYBk","executionInfo":{"status":"ok","timestamp":1667398476716,"user_tz":-180,"elapsed":15,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"567b3e5e-3152-48c5-a490-5a67fdddc39b"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# Input shape --> (Batch Size, Sequence Length, One-Hot Encoding Size)\n","input_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)"],"metadata":{"id":"s_jRMezBo-Fo","executionInfo":{"status":"ok","timestamp":1667397711043,"user_tz":-180,"elapsed":323,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["input_seq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RICV7l53pfCf","executionInfo":{"status":"ok","timestamp":1667397720273,"user_tz":-180,"elapsed":20,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"7c34f993-8393-43b8-ee07-ec47a530031f"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         1., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         1., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.]],\n","\n","       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n","         0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n","         0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.]],\n","\n","       [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 1.],\n","        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n","         0., 0.]]], dtype=float32)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["input_seq = torch.from_numpy(input_seq)\n","target_seq = torch.Tensor(target_seq)"],"metadata":{"id":"PzKd5RfwphLy","executionInfo":{"status":"ok","timestamp":1667398704557,"user_tz":-180,"elapsed":392,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n","is_cuda = torch.cuda.is_available()\n","\n","# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n","if is_cuda:\n","    device = torch.device(\"cuda\")\n","    print(\"GPU is available\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU not available, CPU used\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IWG3nNWStRmI","executionInfo":{"status":"ok","timestamp":1667398906026,"user_tz":-180,"elapsed":19,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"a2a3efb1-6133-443f-b02f-dee0d699419a"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU not available, CPU used\n"]}]},{"cell_type":"code","source":["class Model(nn.Module):\n","  def __init__(self, input_size, output_size, hidden_dim, n_layers):\n","    super(Model, self).__init__()\n","\n","    # Defining some parameters\n","    self.hidden_dim = hidden_dim\n","    self.n_layers = n_layers\n","\n","    # Defining the layers\n","    # RNN Layer\n","    self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)\n","\n","    # Fully connected layer\n","    self.fc = nn.Linear(hidden_dim, output_size)\n","\n","  def forward(self, x):\n","\n","    batch_size = x.size(0)\n","\n","    # Initializing hidden state for first input using method defined below\n","    hidden = self.init_hidden(batch_size)\n","\n","    # Passing in the input and hidden state into the model and obtaining outputs\n","    out, hidden = self.rnn(x, hidden)\n","\n","    # Reshaping the outputs such that it can be fit into the fully connected layer\n","    out = out.contiguous().view(-1, self.hidden_dim)\n","    out = self.fc(out)\n","\n","    return out, hidden\n","\n","  def init_hidden(self, batch_size):\n","    # This method generates the first hidden state of zeros which we'll use in the forward pass\n","    # We'll send the tensor holding the hidden state to the device we specified earlier as well\n","    hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n","    return hidden "],"metadata":{"id":"iwz1In7CuCxw","executionInfo":{"status":"ok","timestamp":1667400025387,"user_tz":-180,"elapsed":20,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# Instantiate the model with hyperparameters\n","model = Model(input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1)\n","# We'll also set the model to the device that we defined earlier (default is CPU)\n","model.to(device)\n","\n","\n","# Define hyperparameters\n","n_epochs = 100\n","lr = 0.01\n","\n","\n","# Define Loss, Optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)"],"metadata":{"id":"T2rBeAKHyUBR","executionInfo":{"status":"ok","timestamp":1667400231983,"user_tz":-180,"elapsed":4,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# Training Run\n","for epoch in range(1, n_epochs + 1):\n","    optimizer.zero_grad() # Clears existing gradients from previous epoch\n","    input_seq.to(device)\n","    output, hidden = model(input_seq)\n","    loss = criterion(output, target_seq.view(-1).long())\n","    loss.backward() # Does backpropagation and calculates gradients\n","    optimizer.step() # Updates the weights accordingly\n","    \n","    if epoch%10 == 0:\n","        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n","        print(\"Loss: {:.4f}\".format(loss.item()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hiJlrK9DzGgb","executionInfo":{"status":"ok","timestamp":1667400318619,"user_tz":-180,"elapsed":1006,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"8db8e5c8-967e-4344-ee5a-3623107de2fb"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 10/100............. Loss: 2.5148\n","Epoch: 20/100............. Loss: 2.0893\n","Epoch: 30/100............. Loss: 1.6282\n","Epoch: 40/100............. Loss: 1.1809\n","Epoch: 50/100............. Loss: 0.8217\n","Epoch: 60/100............. Loss: 0.5566\n","Epoch: 70/100............. Loss: 0.3757\n","Epoch: 80/100............. Loss: 0.2624\n","Epoch: 90/100............. Loss: 0.1937\n","Epoch: 100/100............. Loss: 0.1511\n"]}]},{"cell_type":"code","source":["# This function takes in the model and character as arguments and returns the next character prediction and hidden state\n","def predict(model, character):\n","    # One-hot encoding our input to fit into the model\n","    character = np.array([[char2int[c] for c in character]])\n","    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n","    character = torch.from_numpy(character)\n","    character.to(device)\n","    \n","    out, hidden = model(character)\n","\n","    prob = nn.functional.softmax(out[-1], dim=0).data\n","    # Taking the class with the highest probability score from the output\n","    char_ind = torch.max(prob, dim=0)[1].item()\n","\n","    return int2char[char_ind], hidden"],"metadata":{"id":"isb9fBCUzbgO","executionInfo":{"status":"ok","timestamp":1667400419841,"user_tz":-180,"elapsed":8,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# This function takes the desired output length and input characters as arguments, returning the produced sentence\n","def sample(model, out_len, start='hey'):\n","    model.eval() # eval mode\n","    start = start.lower()\n","    # First off, run through the starting characters\n","    chars = [ch for ch in start]\n","    size = out_len - len(chars)\n","    # Now pass in the previous characters and get a new one\n","    for ii in range(size):\n","        char, h = predict(model, chars)\n","        chars.append(char)\n","\n","    return ''.join(chars)"],"metadata":{"id":"AYbFTGYdz0XX","executionInfo":{"status":"ok","timestamp":1667400471463,"user_tz":-180,"elapsed":429,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["sample(model, 15, 'good')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"PUsGE0cz0A7d","executionInfo":{"status":"ok","timestamp":1667400483636,"user_tz":-180,"elapsed":20,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"33a5906d-aac3-40a8-b9f4-d94f3678d96b"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'good I am fine '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":[],"metadata":{"id":"aPxn-aCC0D5z"},"execution_count":null,"outputs":[]}]}