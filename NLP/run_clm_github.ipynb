{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyMC8f/hD/1reowUguQBFMsW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T-t7Ey7i9610","executionInfo":{"status":"ok","timestamp":1668779158707,"user_tz":-180,"elapsed":44404,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"29489704-6fea-4e07-afe5-3271dbcab128"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.7.0-py3-none-any.whl (451 kB)\n","\u001b[K     |████████████████████████████████| 451 kB 36.3 MB/s \n","\u001b[?25hCollecting evaluate\n","  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n","\u001b[K     |████████████████████████████████| 72 kB 1.8 MB/s \n","\u001b[?25hCollecting transformers[sentencepiece]\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 62.7 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Collecting xxhash\n","  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 100.1 MB/s \n","\u001b[?25hCollecting multiprocess\n","  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 92.9 MB/s \n","\u001b[?25hRequirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Collecting huggingface-hub<1.0.0,>=0.2.0\n","  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 73.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 78.0 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 64.7 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n","Collecting sentencepiece!=0.1.92,>=0.1.91\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 80.6 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf<=3.20.2 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.19.6)\n","Installing collected packages: urllib3, xxhash, tokenizers, responses, multiprocess, huggingface-hub, transformers, sentencepiece, datasets, evaluate\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.7.0 evaluate-0.3.0 huggingface-hub-0.11.0 multiprocess-0.70.14 responses-0.18.0 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.24.0 urllib3-1.25.11 xxhash-3.1.0\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","!pip install datasets evaluate transformers[sentencepiece]"]},{"cell_type":"code","source":["import logging\n","import math\n","import os\n","import sys\n","from dataclasses import dataclass, field\n","from itertools import chain\n","from typing import Optional \n","\n","import datasets\n","from datasets import load_dataset\n","\n","import evaluate\n","import transformers\n","from transformers import (\n","    CONFIG_MAPPING,\n","    MODEL_FOR_MASKED_LM_MAPPING,\n","    AutoConfig,\n","    AutoModelForMaskedLM,\n","    AutoTokenizer,\n","    DataCollatorForLanguageModeling,\n","    HfArgumentParser,\n","    Trainer,\n","    TrainingArguments,\n","    is_torch_tpu_available,\n","    set_seed,\n",")\n","\n","from transformers.trainer_utils import get_last_checkpoint\n","from transformers.utils import check_min_version, send_example_telemetry\n","from transformers.utils.versions import require_version"],"metadata":{"id":"SFYYCjRj-A6i","executionInfo":{"status":"ok","timestamp":1668779163839,"user_tz":-180,"elapsed":5157,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!python run_clm.py \\\n","    --model_name_or_path gpt2 \\\n","    --dataset_name wikitext \\\n","    --dataset_config_name wikitext-2-raw-v1 \\\n","    --per_device_train_batch_size 8 \\\n","    --per_device_eval_batch_size 8 \\\n","    --do_train \\\n","    --do_eval \\\n","    --output_dir /content/test-clm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oELWri45-KMJ","executionInfo":{"status":"ok","timestamp":1668782112679,"user_tz":-180,"elapsed":2190776,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"17ac7ae4-6ad0-4f12-b8bd-b52fdcf5a357"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:__main__:Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","INFO:__main__:Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=no,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=-1,\n","log_level=passive,\n","log_level_replica=passive,\n","log_on_each_node=True,\n","logging_dir=/content/test-clm/runs/Nov18_13-58-45_41d250406d10,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_hf,\n","output_dir=/content/test-clm,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=8,\n","per_device_train_batch_size=8,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=/content/test-clm,\n","save_on_each_node=False,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n","xpu_backend=None,\n",")\n","INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/wikitext/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\n","INFO:datasets.builder:Overwrite dataset info from restored data version.\n","INFO:datasets.info:Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\n","WARNING:datasets.builder:Found cached dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n","INFO:datasets.info:Loading Dataset info from /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126\n","100% 3/3 [00:00<00:00, 957.17it/s]\n","[INFO|configuration_utils.py:654] 2022-11-18 13:58:51,652 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/75e09b43581151bd1d9ef6700faa605df408979f/config.json\n","[INFO|configuration_utils.py:706] 2022-11-18 13:58:51,653 >> Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.24.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","[INFO|tokenization_auto.py:427] 2022-11-18 13:58:52,567 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n","[INFO|configuration_utils.py:654] 2022-11-18 13:58:53,489 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/75e09b43581151bd1d9ef6700faa605df408979f/config.json\n","[INFO|configuration_utils.py:706] 2022-11-18 13:58:53,490 >> Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.24.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","[INFO|tokenization_utils_base.py:1775] 2022-11-18 13:58:55,343 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/75e09b43581151bd1d9ef6700faa605df408979f/vocab.json\n","[INFO|tokenization_utils_base.py:1775] 2022-11-18 13:58:55,343 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/75e09b43581151bd1d9ef6700faa605df408979f/merges.txt\n","[INFO|tokenization_utils_base.py:1775] 2022-11-18 13:58:55,343 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/75e09b43581151bd1d9ef6700faa605df408979f/tokenizer.json\n","[INFO|tokenization_utils_base.py:1775] 2022-11-18 13:58:55,343 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1775] 2022-11-18 13:58:55,343 >> loading file special_tokens_map.json from cache at None\n","[INFO|tokenization_utils_base.py:1775] 2022-11-18 13:58:55,343 >> loading file tokenizer_config.json from cache at None\n","[INFO|configuration_utils.py:654] 2022-11-18 13:58:55,343 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/75e09b43581151bd1d9ef6700faa605df408979f/config.json\n","[INFO|configuration_utils.py:706] 2022-11-18 13:58:55,344 >> Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.24.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","[INFO|modeling_utils.py:2158] 2022-11-18 13:58:55,407 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/75e09b43581151bd1d9ef6700faa605df408979f/pytorch_model.bin\n","[INFO|modeling_utils.py:2608] 2022-11-18 13:58:57,020 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","[INFO|modeling_utils.py:2617] 2022-11-18 13:58:57,020 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-961851c10e659770.arrow\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-914f625d5e5d5024.arrow\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-b7ee3c8123f2d924.arrow\n","Grouping texts in chunks of 512:   0% 0/5 [00:00<?, ?ba/s]INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-2cce424ef3927f67.arrow\n","Grouping texts in chunks of 512: 100% 5/5 [00:00<00:00, 18.06ba/s]\n","Grouping texts in chunks of 512:   0% 0/37 [00:00<?, ?ba/s]INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-d605891295d91264.arrow\n","Grouping texts in chunks of 512: 100% 37/37 [00:02<00:00, 15.57ba/s]\n","Grouping texts in chunks of 512:   0% 0/4 [00:00<?, ?ba/s]INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-89cc8edadbed8c0b.arrow\n","Grouping texts in chunks of 512: 100% 4/4 [00:00<00:00, 17.11ba/s]\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","[INFO|trainer.py:1608] 2022-11-18 13:59:03,645 >> ***** Running training *****\n","[INFO|trainer.py:1609] 2022-11-18 13:59:03,645 >>   Num examples = 4656\n","[INFO|trainer.py:1610] 2022-11-18 13:59:03,645 >>   Num Epochs = 3\n","[INFO|trainer.py:1611] 2022-11-18 13:59:03,645 >>   Instantaneous batch size per device = 8\n","[INFO|trainer.py:1612] 2022-11-18 13:59:03,645 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:1613] 2022-11-18 13:59:03,645 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1614] 2022-11-18 13:59:03,645 >>   Total optimization steps = 1746\n","[INFO|trainer.py:1616] 2022-11-18 13:59:03,646 >>   Number of trainable parameters = 124439808\n","{'loss': 3.3182, 'learning_rate': 3.5681557846506306e-05, 'epoch': 0.86}\n"," 29% 500/1746 [10:06<25:17,  1.22s/it][INFO|trainer.py:2678] 2022-11-18 14:09:10,232 >> Saving model checkpoint to /content/test-clm/checkpoint-500\n","[INFO|configuration_utils.py:447] 2022-11-18 14:09:10,233 >> Configuration saved in /content/test-clm/checkpoint-500/config.json\n","[INFO|modeling_utils.py:1624] 2022-11-18 14:09:11,334 >> Model weights saved in /content/test-clm/checkpoint-500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2125] 2022-11-18 14:09:11,335 >> tokenizer config file saved in /content/test-clm/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2132] 2022-11-18 14:09:11,335 >> Special tokens file saved in /content/test-clm/checkpoint-500/special_tokens_map.json\n","{'loss': 3.1449, 'learning_rate': 2.13631156930126e-05, 'epoch': 1.72}\n"," 57% 1000/1746 [20:21<15:09,  1.22s/it][INFO|trainer.py:2678] 2022-11-18 14:19:24,872 >> Saving model checkpoint to /content/test-clm/checkpoint-1000\n","[INFO|configuration_utils.py:447] 2022-11-18 14:19:24,873 >> Configuration saved in /content/test-clm/checkpoint-1000/config.json\n","[INFO|modeling_utils.py:1624] 2022-11-18 14:19:25,893 >> Model weights saved in /content/test-clm/checkpoint-1000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2125] 2022-11-18 14:19:25,893 >> tokenizer config file saved in /content/test-clm/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2132] 2022-11-18 14:19:25,893 >> Special tokens file saved in /content/test-clm/checkpoint-1000/special_tokens_map.json\n","{'loss': 3.0703, 'learning_rate': 7.0446735395189e-06, 'epoch': 2.58}\n"," 86% 1500/1746 [30:35<04:59,  1.22s/it][INFO|trainer.py:2678] 2022-11-18 14:29:39,226 >> Saving model checkpoint to /content/test-clm/checkpoint-1500\n","[INFO|configuration_utils.py:447] 2022-11-18 14:29:39,227 >> Configuration saved in /content/test-clm/checkpoint-1500/config.json\n","[INFO|modeling_utils.py:1624] 2022-11-18 14:29:40,248 >> Model weights saved in /content/test-clm/checkpoint-1500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2125] 2022-11-18 14:29:40,249 >> tokenizer config file saved in /content/test-clm/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2132] 2022-11-18 14:29:40,249 >> Special tokens file saved in /content/test-clm/checkpoint-1500/special_tokens_map.json\n","100% 1746/1746 [35:40<00:00,  1.22s/it][INFO|trainer.py:1859] 2022-11-18 14:34:44,173 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 2140.5446, 'train_samples_per_second': 6.525, 'train_steps_per_second': 0.816, 'train_loss': 3.159466126257338, 'epoch': 3.0}\n","100% 1746/1746 [35:40<00:00,  1.23s/it]\n","[INFO|trainer.py:2678] 2022-11-18 14:34:44,193 >> Saving model checkpoint to /content/test-clm\n","[INFO|configuration_utils.py:447] 2022-11-18 14:34:44,194 >> Configuration saved in /content/test-clm/config.json\n","[INFO|modeling_utils.py:1624] 2022-11-18 14:34:45,177 >> Model weights saved in /content/test-clm/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2125] 2022-11-18 14:34:45,178 >> tokenizer config file saved in /content/test-clm/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2132] 2022-11-18 14:34:45,178 >> Special tokens file saved in /content/test-clm/special_tokens_map.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  train_loss               =     3.1595\n","  train_runtime            = 0:35:40.54\n","  train_samples            =       4656\n","  train_samples_per_second =      6.525\n","  train_steps_per_second   =      0.816\n","INFO:__main__:*** Evaluate ***\n","[INFO|trainer.py:2929] 2022-11-18 14:34:45,271 >> ***** Running Evaluation *****\n","[INFO|trainer.py:2931] 2022-11-18 14:34:45,271 >>   Num examples = 481\n","[INFO|trainer.py:2934] 2022-11-18 14:34:45,271 >>   Batch size = 8\n","100% 61/61 [00:24<00:00,  2.49it/s]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_accuracy           =     0.4179\n","  eval_loss               =     3.1241\n","  eval_runtime            = 0:00:24.85\n","  eval_samples            =        481\n","  eval_samples_per_second =     19.349\n","  eval_steps_per_second   =      2.454\n","  perplexity              =    22.7391\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n","\n","PATH = \"/content/test-clm\"\n","model = AutoModelForCausalLM.from_pretrained(PATH)\n","tokenizer = AutoTokenizer.from_pretrained(PATH)\n","generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer) "],"metadata":{"id":"AQ_NY6WI-pC4","executionInfo":{"status":"ok","timestamp":1668782596651,"user_tz":-180,"elapsed":2879,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["generator(\"I want to be\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p1v93zdSMZO_","executionInfo":{"status":"ok","timestamp":1668782613558,"user_tz":-180,"elapsed":2216,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"a72f4b58-a8cd-4af0-bb56-5de0ed27b7da"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1364: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 50 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n","  UserWarning,\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'generated_text': 'I want to be able to show what I mean here by not having to have my hair tied down. [ She ] really looks like that girl around here. And I feel like I could have turned that off and left it on for a while,'}]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":[],"metadata":{"id":"nbAGgQoNMdb2"},"execution_count":null,"outputs":[]}]}