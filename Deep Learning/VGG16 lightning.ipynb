{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG16 lightning.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNR75rvfgDd8Bqkcvuk7qcp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T_qLzu_kEPHi","executionInfo":{"status":"ok","timestamp":1659671665291,"user_tz":-180,"elapsed":22571,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"35e19288-988b-46f4-ed95-b828562d4707"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["#!pip install pytorch-lightning"],"metadata":{"id":"b8GG0bR4EwD5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pytorch_lightning as pl\n","import pandas as pd\n","import cv2\n","import os \n","from torch import nn\n","from torch.utils.data import Dataset ,DataLoader, random_split\n","import numpy as np\n","import torch\n","from sklearn.model_selection import train_test_split \n","from torchvision import transforms, datasets\n","import matplotlib.pyplot as plt\n","import torchmetrics\n","from torchmetrics.functional import accuracy\n","from pytorch_lightning.callbacks import LearningRateMonitor\n","from pytorch_lightning.callbacks.progress import TQDMProgressBar\n","from pytorch_lightning.loggers import CSVLogger\n","from torchvision.utils import make_grid\n","import math\n","import torch.nn.functional as F"],"metadata":{"id":"jJSmytHyEbrd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pl.seed_everything(7)\n","PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \"/content/drive/MyDrive/Datasets\")\n","BATCH_SIZE = 256 if torch.cuda.is_available() else 64\n","CLASS_SIZE = 10\n","VAL_SIZE = 10000"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8-wN8eOSEsAP","executionInfo":{"status":"ok","timestamp":1659671693140,"user_tz":-180,"elapsed":357,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"7097a36c-475f-4ce0-de05-939ca2a0d071"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Global seed set to 7\n"]}]},{"cell_type":"code","source":["class Data(pl.LightningDataModule):\n","  def __init__(self, data_dir: str=PATH_DATASETS, batch_size: int=BATCH_SIZE, class_size: int=CLASS_SIZE,\n","               val_size: int=VAL_SIZE):\n","    super().__init__()\n","    self.data_dir = data_dir\n","    self.batch_size = batch_size\n","    self.class_size = class_size\n","    self.val_size = val_size\n","    self.transform = {\n","        'train': transforms.Compose([\n","            transforms.Resize((224,224)),\n","            transforms.RandomHorizontalFlip(p=0.7),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n","        ]),\n","\n","        'test': transforms.Compose([\n","            transforms.Resize((224,224)),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n","        ])\n","    }\n","\n","    \n","\n","  def prepare_data(self):\n","    datasets.CIFAR10(root=self.data_dir, train=True, download=True)\n","    datasets.CIFAR10(root=self.data_dir, train=False, download=True)\n","\n","  def setup(self, stage=None):\n","    if stage == 'fit' or stage is None:\n","      cifar10_full = datasets.CIFAR10(root=self.data_dir, train=True, transform=self.transform['train'])\n","      self.train_size = len(cifar10_full) - self.val_size\n","      self.cifar_train, self.cifar_val = random_split(cifar10_full, [self.train_size, self.val_size])\n","\n","    if stage == 'test' or stage is None:\n","      self.cifar_test = datasets.CIFAR10(root=self.data_dir, train=False, transform=self.transform['test'])\n","\n","  def train_dataloader(self):\n","    return DataLoader(self.cifar_train, batch_size=32, shuffle=True)\n","\n","  def val_dataloader(self):\n","    return DataLoader(self.cifar_val, batch_size=32, shuffle=False)\n","\n","  def test_dataloader(seld):\n","    return DataLoader(self.cifar_test, batch_size=32, shuffle=False)\n","\n","  def visualize(self):\n","    for images, _ in self.train_dataloader():\n","      print(f\"images.shape: {images.shape}\")\n","      plt.figure(figsize=(16,8))\n","      plt.axis(\"off\")\n","      plt.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n","      break"],"metadata":{"id":"MfidfbTIE7Kq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dm = Data()\n","dm.prepare_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f9aliaatAAq-","executionInfo":{"status":"ok","timestamp":1659671871685,"user_tz":-180,"elapsed":3087,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"3ed1477d-89ff-405d-a7a1-1954b217dfbf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["dm.setup()"],"metadata":{"id":"XYUNpPo8AMgv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dm.visualize()"],"metadata":{"id":"0f2e5_7WAPm0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LitVGGNet(pl.LightningModule):\n","  def __init__(self):\n","    super().__init__()\n","    self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n","    self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n","\n","    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n","    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n","\n","    self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n","    self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n","    self.conv7 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n","\n","    self.conv8 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n","    self.conv9 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n","    self.conv10 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n","\n","    self.conv11 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n","    self.conv12 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n","    self.conv13 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n","\n","    self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","    self.fc14 = nn.Linear(in_features=7*7*512, out_features=4096)\n","    self.fc15 = nn.Linear(in_features=4096, out_features=4096)\n","    self.fc16 = nn.Linear(in_features=4096, out_features=10)\n","\n","    self.save_hyperparameters()\n","  \n","  def forward(self, x):\n","    x = F.relu(self.conv1(x))\n","    x = F.relu(self.conv2(x))\n","    x = self.maxpool(x)\n","    x = F.relu(self.conv3(x))\n","    x = F.relu(self.conv4(x))\n","    x = self.maxpool(x)\n","    x = F.relu(self.conv5(x))\n","    x = F.relu(self.conv6(x))\n","    x = F.relu(self.conv7(x))\n","    x = self.maxpool(x)\n","    x = F.relu(self.conv8(x))\n","    x = F.relu(self.conv9(x))\n","    x = F.relu(self.conv10(x))\n","    x = self.maxpool(x)\n","    x = F.relu(self.conv11(x))\n","    x = F.relu(self.conv12(x))\n","    x = F.relu(self.conv13(x))\n","    x = self.maxpool(x)\n","    x = x.view(x.size(0), -1)\n","    x = F.relu(self.fc14(x))\n","    x = F.dropout(x, 0.5)\n","    x = F.relu(self.fc15(x))\n","    x = F.dropout(x, 0.5)\n","    x = F.relu(self.fc16(x))\n","    return x\n","\n","\n","  def training_step(self, batch, batch_idx):\n","    x, y = batch\n","    logits = self.forward(x)\n","    loss = nn.functional.cross_entropy(logits, y)\n","    self.log('train loss', loss)\n","    return loss\n","\n","  def evaluate(self, batch, stage=None):\n","    x, y = batch\n","    logits = self.forward(x)\n","    loss = nn.functional.cross_entropy(logits, y)\n","    preds = torch.argmax(logits, dim=1)\n","    acc = accuracy(preds, y)\n","\n","    if stage:\n","      self.log(f'{stage}_loss', loss, prog_bar=True)\n","      self.log(f'{stage}_acc', acc, prog_bar=True)\n","\n","  def validation_step(self, batch, batch_idx):\n","    self.evaluate(batch, stage=\"val\")\n","\n","  def test_step(self, batch, batch_idx):\n","    self.evaluate(batch, stage=\"test\")\n","\n","  def configure_optimizers(self):\n","    return torch.optim.Adam(self.parameters(), lr=1e-4)"],"metadata":{"id":"ngqbHkudFa-i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = LitVGGNet()\n","trainer = pl.Trainer(max_epochs=10,\n","                  default_root_dir=\"/content/drive/MyDrive/Checkpoints\", \n","                  accelerator=\"auto\",\n","                  devices=1 if torch.cuda.is_available() else None,\n","                  callbacks=[LearningRateMonitor(logging_interval=\"step\"),\n","                                TQDMProgressBar(refresh_rate=10)],\n",")\n","trainer.fit(model, dm)"],"metadata":{"id":"c6_BH4oTGF4T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"3BtYND0qIxFw"},"execution_count":null,"outputs":[]}]}