{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Resnet18 lightning.ipynb","provenance":[],"authorship_tag":"ABX9TyNcmjmE3PTVXsP67wXFfY+2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BPc30elxrrnB","executionInfo":{"status":"ok","timestamp":1659711169990,"user_tz":-180,"elapsed":22069,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"aec5ab42-21a3-48bc-e6c1-15cb5fdec25d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["!pip install pytorch-lightning"],"metadata":{"id":"V5XdYf_qr0Oi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pytorch_lightning as pl\n","import pandas as pd\n","import cv2\n","import os \n","from torch import nn\n","from torch.utils.data import Dataset ,DataLoader, random_split\n","import numpy as np\n","import torch\n","from sklearn.model_selection import train_test_split \n","from torchvision import transforms, datasets, models\n","import matplotlib.pyplot as plt\n","import torchmetrics\n","from torchmetrics.functional import accuracy\n","from pytorch_lightning.callbacks import LearningRateMonitor\n","from pytorch_lightning.callbacks.progress import TQDMProgressBar\n","from pytorch_lightning.loggers import CSVLogger\n","from torchvision.utils import make_grid\n","import math\n","import torch.nn.functional as F"],"metadata":{"id":"RTNLSuPjsKlP","executionInfo":{"status":"ok","timestamp":1659711182718,"user_tz":-180,"elapsed":4459,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["pl.seed_everything(7)\n","PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \"/content/drive/MyDrive/Datasets\")\n","BATCH_SIZE = 32\n","CLASS_SIZE = 10\n","VAL_SIZE = 10000"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vEQdK78NO8ys","executionInfo":{"status":"ok","timestamp":1659711182719,"user_tz":-180,"elapsed":23,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"25981986-015d-45ce-8bc2-a68634b297dc"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.seed:Global seed set to 7\n"]}]},{"cell_type":"code","source":["class LitDataModule(pl.LightningDataModule):\n","  def __init__(self, data_dir=PATH_DATASETS, batch_size=BATCH_SIZE, val_size=VAL_SIZE):\n","    super().__init__()\n","    self.data_dir = data_dir\n","    self.batch_size = batch_size\n","    self.val_size = val_size\n","    self.transform = {\n","        'train': transforms.Compose([\n","            transforms.Resize((224,224)),\n","            transforms.RandomHorizontalFlip(p=0.7),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n","        ]),\n","\n","        'test': transforms.Compose([\n","            transforms.Resize((224,224)),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n","        ])\n","    }\n","\n","  def prepare_data(self):\n","    datasets.CIFAR10(root=self.data_dir, train=True, download=True)\n","    datasets.CIFAR10(root=self.data_dir, train=False, download=True)\n","\n","  def setup(self, stage=None):\n","    if stage=='fit' or stage is None:\n","      cf_full = datasets.CIFAR10(root=self.data_dir, train=True, transform=self.transform['train'])\n","      train_size = len(cf_full) - self.val_size\n","      self.cf_train, self.cf_val = random_split(cf_full, [train_size, self.val_size])\n","\n","    if stage=='test' or stage is None:\n","      self.cf_test = datasets.CIFAR10(root=self.data_dir, train=False, transform=self.transform['test'])\n","\n","  def train_dataloader(self):\n","    return DataLoader(self.cf_train, batch_size=256, shuffle=True)\n","\n","  def val_dataloader(self):\n","    return DataLoader(self.cf_val, batch_size=256, shuffle=False)\n","\n","  def test_dataloader(self):\n","    return DataLoader(self.cf_test, batch_size=256, shuffle=False)\n","\n","  def visualize(self):\n","    for images, _ in self.train_dataloader():\n","      print(f\"images.shape: {images.shape}\")\n","      plt.figure(figsize=(16,8))\n","      plt.axis(\"off\")\n","      plt.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n","      break"],"metadata":{"id":"p0_JyoEVsQgw","executionInfo":{"status":"ok","timestamp":1659711782303,"user_tz":-180,"elapsed":296,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class LitResnet18():\n","  def __init__(self):\n","    super().__init__()\n","    self.save_hyperparameters()\n","    self.num_class = CLASS_SIZE\n","\n","    self\n","\n","\n","  def forward(self, x):\n","    x = self.model(x)\n","    return x\n","\n","  def training_step(self, batch, batch_idx):\n","    x, y = batch\n","    logits = self.forward(x)\n","    loss = nn.functional.cross_entropy(logits, y)\n","    self.log('train loss', loss)\n","    return loss\n","\n","\n","  def evaluate(self, batch, stage=None):\n","    x, y = batch\n","    logits = self.forward(x)\n","    loss = nn.functional.cross_entropy(logits, y)\n","    preds = torch.argmax(logits, dim=1)\n","    acc = accuracy(preds, y)\n","\n","    if stage:\n","      self.log(f'{stage}_loss', loss, prog_bar=True)\n","      self.log(f'{stage}_acc', acc, prog_bar=True)\n","\n","  def validation_step(self, batch, batch_idx):\n","    self.evaluate(batch, stage=\"val\")\n","\n","  def test_step(self, batch, batch_idx):\n","    self.evaluate(batch, stage=\"test\")\n","\n","  def configure_optimizers(self):\n","    return torch.optim.Adam(self.parameters(), lr=1e-4)"],"metadata":{"id":"ZC64ANVasr5l","executionInfo":{"status":"ok","timestamp":1659711783342,"user_tz":-180,"elapsed":3,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["dm = LitDataModule()\n","dm.prepare_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3W-Fa2BwhvDM","executionInfo":{"status":"ok","timestamp":1659712122907,"user_tz":-180,"elapsed":2479,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"cedd803a-7c93-4588-8930-3663208bb5dc"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["dm.setup()"],"metadata":{"id":"ZygCXF67h0Xp","executionInfo":{"status":"ok","timestamp":1659712124447,"user_tz":-180,"elapsed":1548,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["model = get_model()"],"metadata":{"id":"ovjdVWKyiDXu","executionInfo":{"status":"ok","timestamp":1659712124774,"user_tz":-180,"elapsed":332,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["trainer = pl.Trainer(max_epochs=1,\n","                  accelerator=\"auto\",\n","                  devices=1 if torch.cuda.is_available() else None,\n","                  callbacks=[LearningRateMonitor(logging_interval=\"step\"),\n","                                TQDMProgressBar(refresh_rate=20)],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xHC0k9wEiHaa","executionInfo":{"status":"ok","timestamp":1659712153719,"user_tz":-180,"elapsed":753,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"f1df87d2-4911-4242-ecde-dc2feac1d558"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]}]},{"cell_type":"code","source":["trainer.fit(model, dm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ZtBLB-5njaNd","executionInfo":{"status":"error","timestamp":1659712168055,"user_tz":-180,"elapsed":343,"user":{"displayName":"Salih Diril","userId":"17082496140032816528"}},"outputId":"db3ab1af-5374-4f6b-a4fb-5bd0f37f3299"},"execution_count":21,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m         \u001b[0;31m# TODO(awaelchli): Unify both exceptions below, where `KeyboardError` doesn't re-raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    738\u001b[0m         self._ckpt_path = self.__set_ckpt_path(\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_provided\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mlightning_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2117\u001b[0m         \u001b[0;31m# TODO: this is actually an optional return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mlightning_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;34m\"\"\"Returns the pure LightningModule without potential wrappers.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0munwrap_lightning_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/overrides/base.py\u001b[0m in \u001b[0;36munwrap_lightning_module\u001b[0;34m(wrapped_model)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unwrapping the module did not yield a `LightningModule`, got {type(model)} instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Unwrapping the module did not yield a `LightningModule`, got <class 'torchvision.models.resnet.ResNet'> instead.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-d47d1b932123>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         self._call_and_handle_interrupt(\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m         )\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m                 \u001b[0;31m# try syncing remaining processes, kill otherwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconciliate_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_exception\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;31m# teardown might access the stage so we reset it after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_callback_hooks\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1585\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1587\u001b[0;31m         \u001b[0mpl_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1589\u001b[0m             \u001b[0mprev_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mlightning_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlightning_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"pl.LightningModule\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m         \u001b[0;31m# TODO: this is actually an optional return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mlightning_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlightning_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pl.LightningModule\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;34m\"\"\"Returns the pure LightningModule without potential wrappers.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0munwrap_lightning_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_PATH\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/overrides/base.py\u001b[0m in \u001b[0;36munwrap_lightning_module\u001b[0;34m(wrapped_model)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrap_lightning_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unwrapping the module did not yield a `LightningModule`, got {type(model)} instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Unwrapping the module did not yield a `LightningModule`, got <class 'torchvision.models.resnet.ResNet'> instead."]}]},{"cell_type":"code","source":[""],"metadata":{"id":"ZN3g7vUdjdyZ"},"execution_count":null,"outputs":[]}]}